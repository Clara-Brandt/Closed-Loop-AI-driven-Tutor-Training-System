{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U3y0JUEVu_Zu"
      },
      "outputs": [],
      "source": [
        "!pip install google-auth google-auth-httplib2 google-auth-oauthlib google-api-python-client\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install --upgrade google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA5yFjUmrkRm"
      },
      "outputs": [],
      "source": [
        "#Import necessary libraries\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IkheaXGsir1"
      },
      "outputs": [],
      "source": [
        "import openpyxl\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "from google.generativeai.types import RequestOptions\n",
        "from google.api_core import retry\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbiAI6m8sL3J"
      },
      "outputs": [],
      "source": [
        "# Import the API Key (insert key here)\n",
        "GOOGLE_API_KEY=''\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmGkH0WztTIc"
      },
      "source": [
        "# Reading G-Drive Sheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vy8VfjjdtJsh"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet gspread oauth2client google-auth\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "import pandas as pd\n",
        "import google.auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Authorize gspread client\n",
        "# Use google.auth.default() to get credentials\n",
        "credentials, project = google.auth.default()\n",
        "gc = gspread.authorize(credentials)\n",
        "\n",
        "def load_sheet(sheet_id, sheet_name=\"Sheet1\"):\n",
        "    # Load google sheet as dataframe\n",
        "    worksheet = gc.open_by_key(sheet_id).worksheet(sheet_name)\n",
        "    data = worksheet.get_all_values()\n",
        "    df = pd.DataFrame(data[1:], columns=data[0])\n",
        "    return df\n",
        "\n",
        "path = \"1tMmNDWnPTOhAokf0Gi1jPhDZaoqGVThxzfeXbXQnGwQ\"\n",
        "sheet = load_sheet(path,\"Giving Effective Praise Predict_responses\")  # There is only one sheet, so no ambiguity here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uKQIYXct0_j"
      },
      "source": [
        "Get all the responses and scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaaEXbQ_tjSs"
      },
      "outputs": [],
      "source": [
        "INPUT_COLUMN = \"response\" # Specify the column from which input is read (A->1, B->2, etc.)\n",
        "row_count = len(sheet) # Get number of rows. If number of rows to read is already known (or sheet does not terminate where data terminates), place number here (+1) instead.inputs = [sheet.loc[i, INPUT_COLUMN]  for i in range(2, row_count)]  # Column number is set here. YOUR INPUT COLUMN NUMBER GOES HERE.\n",
        "inputs = [sheet.loc[i, INPUT_COLUMN] for i in range(row_count)]\n",
        "inputs = [x for x in inputs if x is not None]\n",
        "print(inputs)\n",
        "print(len(inputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qASEYdU1vH08"
      },
      "source": [
        "# Gemini Prompt Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKg2bQ7qvi_i"
      },
      "source": [
        "Scoring Prompt Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfyoLemuvkrN"
      },
      "outputs": [],
      "source": [
        "GEMINI_SYSTEM_PROMPT = \"\"\"\n",
        "You are a tutor evaluator. Please score the following tutor response to a tutor training scenario involving a middle school student as follows:\n",
        "-if the tutor’s response provides effective, process-focused praise that acknowledges the student’s effort, hard work, perseverance, or focuses on the student’s actions towards the learning process, score with a 1. Examples of responses scoring a 1 are: “Kevin, you didn't give up and you managed to learn, congratulations! Let's finish your math homework together so you can still get a good grade and learn how this kind of homework will be easier sooner.”; “Keep Working.”; “Great job Kevin! You are on the right track, keep working on the problem, you get it!”; “Kevin, that was awesome the way you kept at it and were able to get to the correct answer. You should be proud. Keep up the great work!”; “You're doing a great job working on this paragraph! It can be tricky to find the right words and I think you're doing really well working through it.”\n",
        "-if the tutor's response provides outcomes-based praise, acknowledging only the student’s achievements or outcomes, or does not acknowledge the learning process or effort towards learning, score with a 0. Sample responses scoring a 0 include: “You're doing great, let's see what the next step is.”; “Good Job.”; “I would say she is doing well and let us explore a bit more.”; “I think you are doing great.”; “You can do this! Just take it one step at a time.”\n",
        "Once given a response by the user, please return a JSON string following the format, {\"Rationale\": \"your reasoning here\", \"Score\":0/1}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuVI8e8kxT87"
      },
      "source": [
        "Helper function for response parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIlxCT-ixV5J"
      },
      "outputs": [],
      "source": [
        "def extract_response(response_obj, json=False):\n",
        "  role = response_obj.choices[0].message.role\n",
        "  content = response_obj.choices[0].message.content\n",
        "  if json:\n",
        "    return {\"role\": role, \"content\": content}\n",
        "  else:\n",
        "    return (role, content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIHBTOqTwW1T"
      },
      "source": [
        "## gemini API Call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms4Iojj3wWGw"
      },
      "outputs": [],
      "source": [
        "# Iterate over all responses\n",
        "MAX_TOKENS = 300\n",
        "TEMPERATURE = 0\n",
        "RUN_UP_TO = 250  # Sets a maximum index for responses to run. Useful to specify how many responses we want to run on (partial execution). Set to -1 to run them all.\n",
        "TWO_STAGE = False  # Specifies whether to refine the feedback provided by the scoring prompt\n",
        "TWO_STAGE_INCLUDE_RESPONSE = False # Specifies whether the second-stage prompt uses the original response.\n",
        "SCORE_COLUMN = \"response\"  # Change column numbers here to  modify where output is written\n",
        "\n",
        "\n",
        "MODEL = 'gemini-2.5-pro'\n",
        "model = genai.GenerativeModel(MODEL, system_instruction=GEMINI_SYSTEM_PROMPT)\n",
        "\n",
        "if RUN_UP_TO >=  0:  # If an upper bound is set\n",
        "  inputs_upto = inputs[:RUN_UP_TO]\n",
        "else:\n",
        "  inputs_upto = inputs  # Take the whole set of responses\n",
        "tempScoreList = []\n",
        "tempDirectionList = []\n",
        "tempRationaleList = []\n",
        "retries = []\n",
        "\n",
        "for index, inpt in tqdm(enumerate(inputs_upto), total=len(inputs_upto)):\n",
        "  if index%60 == 0:\n",
        "    time.sleep(30)\n",
        "  generation_prompt = \"Tutor Response: \" + inpt + \"\\n\\n. Your JSON: \" # Gemini Change\n",
        "  generation_config = genai.GenerationConfig(temperature=TEMPERATURE)\n",
        "  # Use client.chat.completions.create instead of client.generate_text\n",
        "  gemini_out = model.generate_content(generation_prompt, generation_config=generation_config,request_options=RequestOptions(retry=retry.Retry(initial=1.0,multiplier=2.0,maximum=60.0))) # TODO: Potential break point\n",
        "  # Extract the content from the response\n",
        "  content = gemini_out.text.lstrip(\"```json\")[:-4]\n",
        "  # We now need to parse the JSON into rational and score\n",
        "  try:\n",
        "    content_json = json.loads(content)  # Run response through JSON\n",
        "    score = str(content_json[\"Score\"])  # Cast to string to avoid type inequality\n",
        "    rationale = str(content_json[\"Rationale\"])  # Fetch the rationale\n",
        "    sheet.at[index,\"GPT Score\"] = score  # Now write both into the dataframe\n",
        "    sheet.at[index,\"GPT Rationale\"] = rationale\n",
        "    tempScoreList.append(score)\n",
        "    tempDirectionList.append(generation_prompt)\n",
        "    tempRationaleList.append(rationale)\n",
        "    #rationale_cell.value = rationale\n",
        "\n",
        "  except:\n",
        "    print(\"error!\")\n",
        "    tempScoreList.append(\"error during LLM evaluation\")\n",
        "    tempRationaleList.append(\"error during LLM evaluation\")\n",
        "    retries.append((index,inpt))\n",
        "  #   score_cell.value = \"---\"\n",
        "  #   rationale_cell.value = \"---\"  # Failsafe\n",
        "  #   if TWO_STAGE:\n",
        "  #     refined_feedback_cell.value = \"---\"\n",
        "print(tempScoreList)\n",
        "print(tempDirectionList)\n",
        "print(tempRationaleList)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get response for skipped question due to error\n",
        "with open(\"/content/drive/Shareddrives/PLUS/Research/Clara Stuff/Gemini Old Standby Scoring/Giving_Effective_Praise_Gemini_Predict_Eval.csv\") as outputFile:\n",
        "  frame = pd.read_csv(outputFile)\n",
        "  rowMissing = frame[(frame[\"TutorID\"]==\"Stu_32de3abaef3bd1133ead729ff52d2f51\") & (frame[\"Lesson\"]==\"Giving Effective Praise\") & (frame[\"Scenario\"]==\"Scenario Carla\")]\n",
        "  print(\"Row:\", rowMissing)\n",
        "\n",
        "  TEMPERATURE = 0\n",
        "  MODEL = 'gemini-2.5-pro'\n",
        "  model = genai.GenerativeModel(MODEL, system_instruction=GEMINI_SYSTEM_PROMPT)\n",
        "\n",
        "\n",
        "  generation_prompt = \"Tutor Response: \" + rowMissing[\"response\"].unique()[0] + \"\\n\\n. Your JSON: \"\n",
        "  print(\"Prompt:\", generation_prompt)\n",
        "  generation_config = genai.GenerationConfig(temperature=TEMPERATURE)\n",
        "  # Use client.chat.completions.create instead of client.generate_text\n",
        "  gemini_out = model.generate_content(generation_prompt, generation_config=generation_config)\n",
        "  print(gemini_out)\n",
        "  # Extract the content from the response\n",
        "  content = gemini_out.text.lstrip(\"```json\")[:-4]\n",
        "  content_json = json.loads(content)  # Run response through JSON\n",
        "  score = str(content_json[\"Score\"])  # Cast to string to avoid type inequality\n",
        "  rationale = str(content_json[\"Rationale\"])  # Fetch the rationale\n",
        "  frame.at[rowMissing.index[0],\"GPT Score\"] = score  # Now write both into the dataframe\n",
        "  frame.at[rowMissing.index[0],\"GPT Rationale\"] = rationale"
      ],
      "metadata": {
        "id": "ApSu0zGtEz3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(frame[rowMissing.index[0]-1:rowMissing.index[0]+2])"
      ],
      "metadata": {
        "id": "LRY-iRi_GGo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXIjAG544f3I"
      },
      "outputs": [],
      "source": [
        "print(tempScoreList)\n",
        "print(tempRationaleList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUPYEvCt4bP9"
      },
      "outputs": [],
      "source": [
        "for i in range(len(inputs_upto)):\n",
        "  print(inputs_upto[i])\n",
        "  print(tempScoreList[i])\n",
        "  print(tempRationaleList[i])\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzJmfvbvUaiU"
      },
      "outputs": [],
      "source": [
        "print(list(sheet[\"GPT Score\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7MWojh7Y0pg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvd9C9skROrl"
      },
      "source": [
        "## Save G-Drive Sheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GckhEy2oRNme"
      },
      "outputs": [],
      "source": [
        "sheet.to_csv('/content/drive/Shareddrives/PLUS/Research/Clara Stuff/Giving_Effective_Praise_Gemini_Predict_Eval.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}